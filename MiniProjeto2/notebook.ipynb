{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-26T19:37:04.363492Z",
     "iopub.status.busy": "2020-11-26T19:37:04.362757Z",
     "iopub.status.idle": "2020-11-26T19:37:05.830323Z",
     "shell.execute_reply": "2020-11-26T19:37:05.829023Z"
    },
    "id": "43lZ34AM-r8n",
    "papermill": {
     "duration": 1.479173,
     "end_time": "2020-11-26T19:37:05.830461",
     "exception": false,
     "start_time": "2020-11-26T19:37:04.351288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T19:37:05.853522Z",
     "iopub.status.busy": "2020-11-26T19:37:05.851698Z",
     "iopub.status.idle": "2020-11-26T19:37:05.854258Z",
     "shell.execute_reply": "2020-11-26T19:37:05.854776Z"
    },
    "id": "5UzvCV6C-r9I",
    "papermill": {
     "duration": 0.017316,
     "end_time": "2020-11-26T19:37:05.854937",
     "exception": false,
     "start_time": "2020-11-26T19:37:05.837621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def labelizer(labels):\n",
    "    result = torch.empty(len(labels), 10)\n",
    "    for idx, label in enumerate(labels):\n",
    "        aux = torch.zeros(1, 10)\n",
    "        aux[0][label] = 1\n",
    "        result[idx]= aux\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T19:37:05.878548Z",
     "iopub.status.busy": "2020-11-26T19:37:05.877745Z",
     "iopub.status.idle": "2020-11-26T19:37:05.880912Z",
     "shell.execute_reply": "2020-11-26T19:37:05.880375Z"
    },
    "id": "-h0LS2_5-r9M",
    "papermill": {
     "duration": 0.019265,
     "end_time": "2020-11-26T19:37:05.881033",
     "exception": false,
     "start_time": "2020-11-26T19:37:05.861768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_output(outputs, labels):\n",
    "    result = torch.empty(len(outputs), 1)\n",
    "    \n",
    "    for idx, (out, label) in enumerate(zip(outputs, labels)):\n",
    "        result[idx] = out[label]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_test_output(outputs, labels):\n",
    "    result = torch.empty(len(outputs), 1)\n",
    "    \n",
    "    for idx, (out, label) in enumerate(zip(outputs, labels)):\n",
    "        out_list = out.tolist()\n",
    "        result[idx] = 1 if out_list.index(max(out_list)) == label.item() else 0\n",
    "     \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T19:37:08.902613Z",
     "iopub.status.busy": "2020-11-26T19:37:08.900692Z",
     "iopub.status.idle": "2020-11-26T19:37:08.903458Z",
     "shell.execute_reply": "2020-11-26T19:37:08.90401Z"
    },
    "id": "veQ7bQ81-r9Z",
    "papermill": {
     "duration": 0.030544,
     "end_time": "2020-11-26T19:37:08.904135",
     "exception": false,
     "start_time": "2020-11-26T19:37:08.873591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        self.conv_block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, padding=1, padding_mode='reflect'),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=2, padding=0, stride=2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.linear_block1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(64*14*14, 1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.linear_block2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1024, 10),\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.conv_block(input)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_block1(x)\n",
    "        x = self.linear_block2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTPcSta2_wbC"
   },
   "outputs": [],
   "source": [
    "def train_loop(train_data, batch_size):\n",
    "    net.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for idx, (input, label) in enumerate(train_loader, start=1):\n",
    "        optimizer.zero_grad()\n",
    "        out = net(input.to(DEVICE))\n",
    "        prob_out = get_train_output(out, label)\n",
    "        loss = loss_fn(prob_out.to(DEVICE), torch.ones(len(out), 1).to(DEVICE))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if idx > 32000/batch_size:\n",
    "            break\n",
    "    return running_loss / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwqQSFoz_tFy"
   },
   "outputs": [],
   "source": [
    "def test_loop(test_data):\n",
    "    net.eval()\n",
    "    running_loss = 0\n",
    "    hits = 0\n",
    "    out_size = 0\n",
    "    \n",
    "    for idx, (input, label) in enumerate(train_loader, start=1):\n",
    "        out = net(input.to(DEVICE))\n",
    "        prob_out = get_train_output(out, label)\n",
    "        binary_out = get_test_output(out, label)\n",
    "        loss = loss_fn(prob_out.to(DEVICE), torch.ones(len(out), 1).to(DEVICE))\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        hits += torch.sum(binary_out).item()\n",
    "        out_size += len(binary_out)\n",
    "        if idx > 4:\n",
    "            break\n",
    "    return hits / out_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T19:37:08.951571Z",
     "iopub.status.busy": "2020-11-26T19:37:08.950222Z",
     "iopub.status.idle": "2020-11-26T20:08:48.346202Z",
     "shell.execute_reply": "2020-11-26T20:08:48.347399Z"
    },
    "id": "hZIzEG1R-r9c",
    "papermill": {
     "duration": 1899.428869,
     "end_time": "2020-11-26T20:08:48.347599",
     "exception": false,
     "start_time": "2020-11-26T19:37:08.91873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(batch_size):\n",
    "  train_loader = torch.utils.data.DataLoader(torchvision.datasets.QMNIST('./',\n",
    "                                                                        download=True, \n",
    "                                                                        train=True, \n",
    "                                                                        transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()])),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=2,\n",
    "                                            )\n",
    "\n",
    "  test_loader = torch.utils.data.DataLoader(torchvision.datasets.QMNIST('./',\n",
    "                                                                        download=True, \n",
    "                                                                        train=False, \n",
    "                                                                        transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()])),\n",
    "                                            batch_size=1024,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=2,\n",
    "                                            )\n",
    "  \n",
    "  return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5JsRLwxp_m8W",
    "outputId": "103df48d-9012-44d6-dfa6-d56880b0f84b"
   },
   "outputs": [],
   "source": [
    "BATCHES = [16, 32, 64, 128]\n",
    "LEARNING_RATES = [0.01, 0.1, 1]\n",
    "MOMENTUMS = [0.01, 0.1, 1]\n",
    "writer = SummaryWriter()\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "out_dicts = []\n",
    "for bs in BATCHES:\n",
    "  train_loader, test_loader = get_data(bs)\n",
    "  #print(train_loader.shape)\n",
    "  #print(test_loader.shape)\n",
    "  for lr in LEARNING_RATES:\n",
    "    for mom in MOMENTUMS:\n",
    "      net = model().to(DEVICE)\n",
    "      loss_fn = torch.nn.MSELoss()\n",
    "      optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=mom)\n",
    "      \n",
    "      training_loss = []\n",
    "      training_acc = []\n",
    "      start = time.time()\n",
    "      tmp_dict = {}\n",
    "      for epoch in range(30):\n",
    "        loss = train_loop(train_loader, bs)\n",
    "        training_loss.append(loss)\n",
    "        writer.add_scalars('loss_lr'+str(lr)+'_mom'+str(mom), {'batch_size '+str(bs):loss}, epoch+1)\n",
    "\n",
    "        test_acc = test_loop(test_loader)\n",
    "        writer.add_scalars('test_acc_lr'+str(lr)+'_mom'+str(mom), {'batch_size '+str(bs):test_acc}, epoch+1)\n",
    "        training_acc.append(test_acc)\n",
    "        \n",
    "        run_time = time.time() - start\n",
    "\n",
    "        print(f'LR: {lr}, MOM: {mom}, BS: {bs}')\n",
    "        print(f'{epoch} epochs  in {run_time} sec')\n",
    "        print(f'Accuracy: {max(training_acc)}')\n",
    "        print('----------------------------------------------')\n",
    "        \n",
    "        tmp_dict['LR'] = lr\n",
    "        tmp_dict['MOM'] = mom\n",
    "        tmp_dict['BS'] = bs\n",
    "        tmp_dict['Epochs'] = epoch\n",
    "        tmp_dict['Acc'] = max(training_acc)\n",
    "        tmp_dict['Time'] = run_time\n",
    "        out_dicts.append(tmp_dict)\n",
    "        if max(training_acc) > (1- 1e-3):\n",
    "            break\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUJW8-D05nK4"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(out_dicts)\n",
    "df.head()\n",
    "df.to_csv('out.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
