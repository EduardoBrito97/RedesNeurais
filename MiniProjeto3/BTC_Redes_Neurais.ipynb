{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BTC Redes Neurais V2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmPi0F4acbDb",
        "outputId": "d0cd54bb-099c-4aa5-fd17-2b8219444ac7"
      },
      "source": [
        "#install all the required dependancy libraries\n",
        "!pip install torch\n",
        "\n",
        "#importing the libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch as torch\n",
        "from torch.utils import data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import io\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "WsUX28KMXRcr",
        "outputId": "fbc3cdb8-f23b-420f-8598-c649d4199880"
      },
      "source": [
        "btc = pd.read_csv('btc.csv')\n",
        "btc.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Symbol</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume From</th>\n",
              "      <th>Volume To</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5/26/2018</td>\n",
              "      <td>BTCUSD</td>\n",
              "      <td>7459.11</td>\n",
              "      <td>7640.46</td>\n",
              "      <td>7380.00</td>\n",
              "      <td>7520.00</td>\n",
              "      <td>2722.80</td>\n",
              "      <td>2.042265e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5/25/2018</td>\n",
              "      <td>BTCUSD</td>\n",
              "      <td>7584.15</td>\n",
              "      <td>7661.85</td>\n",
              "      <td>7326.94</td>\n",
              "      <td>7459.11</td>\n",
              "      <td>8491.93</td>\n",
              "      <td>6.342069e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5/24/2018</td>\n",
              "      <td>BTCUSD</td>\n",
              "      <td>7505.00</td>\n",
              "      <td>7734.99</td>\n",
              "      <td>7269.00</td>\n",
              "      <td>7584.15</td>\n",
              "      <td>11033.72</td>\n",
              "      <td>8.293137e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5/23/2018</td>\n",
              "      <td>BTCUSD</td>\n",
              "      <td>7987.70</td>\n",
              "      <td>8030.00</td>\n",
              "      <td>7433.19</td>\n",
              "      <td>7505.00</td>\n",
              "      <td>14905.99</td>\n",
              "      <td>1.148104e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5/22/2018</td>\n",
              "      <td>BTCUSD</td>\n",
              "      <td>8393.44</td>\n",
              "      <td>8400.00</td>\n",
              "      <td>7950.00</td>\n",
              "      <td>7987.70</td>\n",
              "      <td>6589.43</td>\n",
              "      <td>5.389753e+07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  Symbol     Open  ...    Close  Volume From     Volume To\n",
              "0  5/26/2018  BTCUSD  7459.11  ...  7520.00      2722.80  2.042265e+07\n",
              "1  5/25/2018  BTCUSD  7584.15  ...  7459.11      8491.93  6.342069e+07\n",
              "2  5/24/2018  BTCUSD  7505.00  ...  7584.15     11033.72  8.293137e+07\n",
              "3  5/23/2018  BTCUSD  7987.70  ...  7505.00     14905.99  1.148104e+08\n",
              "4  5/22/2018  BTCUSD  8393.44  ...  7987.70      6589.43  5.389753e+07\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POB_SHlrwcuT"
      },
      "source": [
        "class LoadData(data.Dataset):\n",
        "    def __init__(self, dataset_dir, window_size=7, train=True):\n",
        "        btc = pd.read_csv(dataset_dir)\n",
        "        data_to_use=btc['Close'].values\n",
        "        scaler = StandardScaler()\n",
        "        scaled_data = scaler.fit_transform(data_to_use.reshape(-1, 1))\n",
        "        X, y = self.window_data(scaled_data, window_size)\n",
        "        if train:\n",
        "            self.data  = np.array(X[:1018]).astype(np.double)\n",
        "            self.label = np.array(y[:1018]).astype(np.double)\n",
        "            self.dataset_size = self.data.shape[0]\n",
        "        else:\n",
        "            self.data = np.array(X[1018:]).astype(np.double)\n",
        "            self.label = np.array(y[1018:]).astype(np.double)\n",
        "            self.dataset_size = self.data.shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.label[idx] \n",
        "\n",
        "    def window_data(self, data, window_size):\n",
        "        X = []\n",
        "        y = []\n",
        "    \n",
        "        i = 0\n",
        "        while (i + window_size) <= len(data) - 1:\n",
        "            X.append(data[i:i+window_size])\n",
        "            y.append(data[i+window_size])\n",
        "            \n",
        "            i += 1\n",
        "        assert len(X) ==  len(y)\n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3jxv_PCUt-p"
      },
      "source": [
        "class LSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_feat=1, num_layers=100, seq_len=7, hidden_cell=None, output_size=1):\n",
        "        super().__init__()\n",
        "        self.hidden_layer_size = num_layers\n",
        "\n",
        "        self.lstm = torch.nn.LSTM(input_size=input_size, hidden_size=hidden_feat, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        self.linear = torch.nn.Linear(seq_len, output_size)\n",
        "\n",
        "        self.hidden_cell = hidden_cell\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        lstm_out, self.hidden_cell = self.lstm(input_seq)\n",
        "        lstm_out = lstm_out.permute(0,2,1)\n",
        "        predictions = self.linear(lstm_out)\n",
        "        return predictions[:,:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWKD9aKDW_ca",
        "outputId": "646e45fd-e909-4af6-b196-743d1a837bf5"
      },
      "source": [
        "dataset = LoadData('btc.csv', window_size=7)\n",
        "dataset[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1.32443891],\n",
              "        [1.30836052],\n",
              "        [1.34137813],\n",
              "        [1.32047807],\n",
              "        [1.44793806],\n",
              "        [1.55507627],\n",
              "        [1.5876661 ]]), array([1.51339762]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb1UAKMCx8Nz"
      },
      "source": [
        "def load_loaders(window_size):\n",
        "    train_dataset = LoadData('btc.csv', window_size=window_size)\n",
        "    train_loader = data.DataLoader(dataset=train_dataset, batch_size=w, drop_last=True)\n",
        "    val_dataset = LoadData('btc.csv', window_size=window_size,train=False)\n",
        "    val_loader = data.DataLoader(dataset=val_dataset, batch_size=1, drop_last=True)\n",
        "    return train_loader, val_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0675n9G2ZFh"
      },
      "source": [
        "def load_optimizer(model,lr):\n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr=lr)\n",
        "    #optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    return optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBMwu8K43-Db"
      },
      "source": [
        "def eval_val_loss(model, dataset, criterion, device):\n",
        "    val_loss, n_batch = 0, 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for train_data in dataset:\n",
        "            x, y = [x.to(device) for x in train_data]\n",
        "            \n",
        "            #x = x.permute(0, 2, 1)\n",
        "            y_out= model(x)\n",
        "            #y_out_unsqueeze = y_out[:,-1,-1].unsqueeze(-1)\n",
        "            #value = criterion(y_out_unsqueeze, y)\n",
        "            value = criterion(y_out, y)\n",
        "            val_loss += value\n",
        "\n",
        "            n_batch += 1\n",
        "    \n",
        "    return val_loss/n_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YSu6WdF2CsB"
      },
      "source": [
        "def train(model, device, criterion, train_loader, optimizer, epoch, writer, params):\n",
        "    # set model to training mode.\n",
        "    steps = 0\n",
        "    model.train()\n",
        "    #h0 = torch.randn(params['window'], 7, params['hiden_layers']).to(device) # H da primeira célula (num_layers * num_directions, batch, hidden_size)\n",
        "    #c0 = torch.randn(params['window'], 7, params['hiden_layers']).to(device) # C da primeira célula (num_layers * num_directions, batch, hidden_size)\n",
        "    avg_loss = 0\n",
        "    for train_data in train_loader:\n",
        "        # move to GPU, if available\n",
        "        x, y = [x.to(device) for x in train_data]\n",
        "        # clear the gradients of all optimized variables.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # compute model output and loss.\n",
        "        y_out = model(x.double()) #, (h0.double(),c0.double()))\n",
        "        #import pdb;pdb.set_trace()\n",
        "        #y_out_unsqueeze = y_out[:,-1,-1].unsqueeze(-1)\n",
        "        #loss = criterion(y_out_unsqueeze, y)\n",
        "        loss = criterion(y, y_out)\n",
        "            \n",
        "        # compute gradient of the loss with respect to model parameters.\n",
        "        loss.backward()\n",
        "        # performs updates using calculated gradients.\n",
        "        optimizer.step()\n",
        "        avg_loss += loss.item()\n",
        "\n",
        "        steps += 1\n",
        "\n",
        "    # write train loss on tensorboard.\n",
        "    writer.add_scalars('loss_lr'+str(params['lr'])+'_hlayers_'+str(params['h']), {'window_'+str(params['window']):avg_loss/steps}, epoch+1)\n",
        "    return avg_loss/steps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHr3b3H84-1Z"
      },
      "source": [
        "def test(model, device, criterion, val_loader, epoch, writer, params):\n",
        "    val_loss = eval_val_loss(model, val_loader, criterion, device)\n",
        "    \n",
        "    # write validation loss on tensorboard.\n",
        "    writer.add_scalars('test_loss_lr'+str(params['lr'])+'_hlayers_'+str(params['h']), {'window_'+str(params['window']):val_loss}, epoch+1)\n",
        "    return val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY-cjCl75OjX",
        "outputId": "50cf0f26-fcce-44cd-dcea-01f0f52f0c69"
      },
      "source": [
        "window_sizes = [7, 14]\n",
        "lrs = [ 0.001, 0.01]\n",
        "hiden_layers = [1,7,14]\n",
        "criterion = torch.nn.MSELoss()\n",
        "writer = SummaryWriter()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "for w in window_sizes:\n",
        "  for l in lrs:\n",
        "    for h in hiden_layers:\n",
        "        #print('w:'+str(w),'l:'+str(l),'h:'+str(h))\n",
        "        hidden_cell = (torch.zeros(params['h'],params['window'],1).double().to(device),\n",
        "                       torch.zeros(params['h'],params['window'],1).double().to(device))\n",
        "        train_loader, val_loader = load_loaders(w)\n",
        "        model = LSTM(input_size=1, hidden_feat=1, num_layers=h, hidden_cell=hidden_cell, seq_len=w).double().to(device)\n",
        "        optimizer = load_optimizer(model,l)\n",
        "        params = {}\n",
        "        with tqdm(total=150) as t:\n",
        "            for epoch in range(150):\n",
        "                params['lr'] = l\n",
        "                params['window'] = w\n",
        "                params['h'] = h\n",
        "                train_loss = train(model, device, criterion, train_loader, optimizer, epoch, writer, params)\n",
        "                val_loss = test(model, device, criterion, val_loader, epoch, writer, params)\n",
        "                loss_postfix = {'train_loss':'{:05.6f}'.format(train_loss),'val_loss':'{:05.6f}'.format(val_loss)}\n",
        "                t.set_postfix(loss_postfix)\n",
        "                t.update()\n",
        "            \n",
        "        print(\"===> Epochs Complete: Train Loss: {}. Val Loss {}\".format(train_loss, val_loss), end=' ')\n",
        "writer.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [01:05<00:00,  2.30it/s, train_loss=0.012893, val_loss=0.000016]\n",
            "  0%|          | 0/150 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===> Epochs Complete: Train Loss: 0.01289287882161587. Val Loss 1.5885606459320904e-05 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [02:45<00:00,  1.11s/it, train_loss=0.048743, val_loss=0.000133]\n",
            "  0%|          | 0/150 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===> Epochs Complete: Train Loss: 0.048742938269116. Val Loss 0.0001328748382501978 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [04:44<00:00,  1.89s/it, train_loss=1.148124, val_loss=0.482973]\n",
            "  0%|          | 0/150 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===> Epochs Complete: Train Loss: 1.1481238303533063. Val Loss 0.4829725048968736 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [01:05<00:00,  2.30it/s, train_loss=0.009136, val_loss=0.000062]\n",
            "  0%|          | 0/150 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===> Epochs Complete: Train Loss: 0.00913646639664745. Val Loss 6.204844706276891e-05 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [02:47<00:00,  1.12s/it, train_loss=1.246531, val_loss=0.219535]\n",
            "  0%|          | 0/150 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===> Epochs Complete: Train Loss: 1.2465311329096722. Val Loss 0.21953476684127843 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [04:44<00:00,  1.89s/it, train_loss=1.246531, val_loss=0.219534]\n",
            "  0%|          | 0/150 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===> Epochs Complete: Train Loss: 1.2465311409254018. Val Loss 0.21953447518922986 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [00:46<00:00,  3.20it/s, train_loss=0.029258, val_loss=0.001306]\n",
            "  0%|          | 0/150 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===> Epochs Complete: Train Loss: 0.029257706400694448. Val Loss 0.0013063988869840932 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [02:12<00:00,  1.13it/s, train_loss=0.086773, val_loss=0.000109]\n",
            "  0%|          | 0/150 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===> Epochs Complete: Train Loss: 0.08677284843446702. Val Loss 0.00010885686907167177 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [03:49<00:00,  1.53s/it, train_loss=1.137007, val_loss=0.496487]\n",
            "  0%|          | 0/150 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===> Epochs Complete: Train Loss: 1.1370070848206455. Val Loss 0.4964867864159309 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [00:47<00:00,  3.19it/s, train_loss=0.030419, val_loss=0.000222]\n",
            "  0%|          | 0/150 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===> Epochs Complete: Train Loss: 0.030419445496868765. Val Loss 0.00022225715067018126 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [02:12<00:00,  1.13it/s, train_loss=1.208369, val_loss=0.372615]\n",
            "  0%|          | 0/150 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===> Epochs Complete: Train Loss: 1.208368985502319. Val Loss 0.3726153592074235 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [03:49<00:00,  1.53s/it, train_loss=1.208374, val_loss=0.372614]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===> Epochs Complete: Train Loss: 1.2083738318462616. Val Loss 0.37261439594031576 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8yckbxtTBKN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86ef44b4-fd3a-404e-95bd-1686e8110319"
      },
      "source": [
        "!zip -r /content/file.zip /content/runs\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/runs/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-41-45_8b696378d8c0/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-41-45_8b696378d8c0/events.out.tfevents.1617187305.8b696378d8c0.66.4 (deflated 5%)\n",
            "  adding: content/runs/Mar31_10-39-40_8b696378d8c0/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-39-40_8b696378d8c0/events.out.tfevents.1617187180.8b696378d8c0.66.3 (deflated 5%)\n",
            "  adding: content/runs/Mar31_10-57-51_8b696378d8c0/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-57-51_8b696378d8c0/loss_lr0.001_hlayers_1_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-57-51_8b696378d8c0/loss_lr0.001_hlayers_1_window_7/events.out.tfevents.1617188273.8b696378d8c0.66.13 (deflated 10%)\n",
            "  adding: content/runs/Mar31_10-57-51_8b696378d8c0/test_loss_lr0.001_hlayers_1_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-57-51_8b696378d8c0/test_loss_lr0.001_hlayers_1_window_7/events.out.tfevents.1617188273.8b696378d8c0.66.14 (deflated 10%)\n",
            "  adding: content/runs/Mar31_10-57-51_8b696378d8c0/events.out.tfevents.1617188271.8b696378d8c0.66.12 (deflated 5%)\n",
            "  adding: content/runs/Mar31_10-58-39_8b696378d8c0/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-58-39_8b696378d8c0/loss_lr0.001_hlayers_1_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-58-39_8b696378d8c0/loss_lr0.001_hlayers_1_window_7/events.out.tfevents.1617188320.8b696378d8c0.66.16 (deflated 9%)\n",
            "  adding: content/runs/Mar31_10-58-39_8b696378d8c0/test_loss_lr0.001_hlayers_1_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-58-39_8b696378d8c0/test_loss_lr0.001_hlayers_1_window_7/events.out.tfevents.1617188320.8b696378d8c0.66.17 (deflated 10%)\n",
            "  adding: content/runs/Mar31_10-58-39_8b696378d8c0/events.out.tfevents.1617188319.8b696378d8c0.66.15 (deflated 5%)\n",
            "  adding: content/runs/Mar31_10-33-48_8b696378d8c0/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-33-48_8b696378d8c0/events.out.tfevents.1617186828.8b696378d8c0.66.0 (deflated 5%)\n",
            "  adding: content/runs/Mar31_10-38-20_8b696378d8c0/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-38-20_8b696378d8c0/events.out.tfevents.1617187100.8b696378d8c0.66.1 (deflated 5%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.001_hlayers_1_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.001_hlayers_1_window_7/events.out.tfevents.1617188444.8b696378d8c0.66.22 (deflated 72%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.001_hlayers_7_window_14/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.001_hlayers_7_window_14/events.out.tfevents.1617189523.8b696378d8c0.66.37 (deflated 73%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.001_hlayers_1_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.001_hlayers_1_window_7/events.out.tfevents.1617188444.8b696378d8c0.66.23 (deflated 73%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.001_hlayers_14_window_14/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.001_hlayers_14_window_14/events.out.tfevents.1617189656.8b696378d8c0.66.39 (deflated 73%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.01_hlayers_14_window_14/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.01_hlayers_14_window_14/events.out.tfevents.1617190065.8b696378d8c0.66.44 (deflated 73%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.001_hlayers_1_window_14/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.001_hlayers_1_window_14/events.out.tfevents.1617189476.8b696378d8c0.66.35 (deflated 73%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.01_hlayers_7_window_14/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.01_hlayers_7_window_14/events.out.tfevents.1617189932.8b696378d8c0.66.42 (deflated 73%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.01_hlayers_1_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.01_hlayers_1_window_7/events.out.tfevents.1617188959.8b696378d8c0.66.28 (deflated 71%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.01_hlayers_1_window_14/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.01_hlayers_1_window_14/events.out.tfevents.1617189884.8b696378d8c0.66.40 (deflated 71%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.001_hlayers_7_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.001_hlayers_7_window_7/events.out.tfevents.1617188510.8b696378d8c0.66.25 (deflated 73%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/events.out.tfevents.1617188443.8b696378d8c0.66.21 (deflated 5%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.01_hlayers_1_window_14/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.01_hlayers_1_window_14/events.out.tfevents.1617189885.8b696378d8c0.66.41 (deflated 73%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.01_hlayers_14_window_14/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.01_hlayers_14_window_14/events.out.tfevents.1617190065.8b696378d8c0.66.45 (deflated 74%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.001_hlayers_7_window_14/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.001_hlayers_7_window_14/events.out.tfevents.1617189523.8b696378d8c0.66.36 (deflated 71%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.01_hlayers_1_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.01_hlayers_1_window_7/events.out.tfevents.1617188959.8b696378d8c0.66.29 (deflated 73%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.01_hlayers_7_window_14/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.01_hlayers_7_window_14/events.out.tfevents.1617189932.8b696378d8c0.66.43 (deflated 74%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.01_hlayers_14_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.01_hlayers_14_window_7/events.out.tfevents.1617189193.8b696378d8c0.66.32 (deflated 73%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.01_hlayers_7_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.01_hlayers_7_window_7/events.out.tfevents.1617189025.8b696378d8c0.66.31 (deflated 75%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.01_hlayers_14_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.01_hlayers_14_window_7/events.out.tfevents.1617189193.8b696378d8c0.66.33 (deflated 73%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.001_hlayers_7_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.001_hlayers_7_window_7/events.out.tfevents.1617188509.8b696378d8c0.66.24 (deflated 71%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.001_hlayers_14_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.001_hlayers_14_window_7/events.out.tfevents.1617188676.8b696378d8c0.66.26 (deflated 73%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.001_hlayers_14_window_14/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.001_hlayers_14_window_14/events.out.tfevents.1617189655.8b696378d8c0.66.38 (deflated 73%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.001_hlayers_14_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/test_loss_lr0.001_hlayers_14_window_7/events.out.tfevents.1617188676.8b696378d8c0.66.27 (deflated 73%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.01_hlayers_7_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.01_hlayers_7_window_7/events.out.tfevents.1617189024.8b696378d8c0.66.30 (deflated 74%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.001_hlayers_1_window_14/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-43_8b696378d8c0/loss_lr0.001_hlayers_1_window_14/events.out.tfevents.1617189476.8b696378d8c0.66.34 (deflated 72%)\n",
            "  adding: content/runs/Mar31_10-45-06_8b696378d8c0/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-45-06_8b696378d8c0/events.out.tfevents.1617187506.8b696378d8c0.66.6 (deflated 5%)\n",
            "  adding: content/runs/Mar31_10-38-58_8b696378d8c0/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-38-58_8b696378d8c0/events.out.tfevents.1617187138.8b696378d8c0.66.2 (deflated 5%)\n",
            "  adding: content/runs/Mar31_10-44-42_8b696378d8c0/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-44-42_8b696378d8c0/events.out.tfevents.1617187482.8b696378d8c0.66.5 (deflated 5%)\n",
            "  adding: content/runs/Mar31_10-46-08_8b696378d8c0/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-46-08_8b696378d8c0/loss_lr0.001_hlayers_1_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-46-08_8b696378d8c0/loss_lr0.001_hlayers_1_window_7/events.out.tfevents.1617187568.8b696378d8c0.66.8 (deflated 71%)\n",
            "  adding: content/runs/Mar31_10-46-08_8b696378d8c0/events.out.tfevents.1617187568.8b696378d8c0.66.7 (deflated 5%)\n",
            "  adding: content/runs/Mar31_10-46-08_8b696378d8c0/test_loss_lr0.001_hlayers_1_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-46-08_8b696378d8c0/test_loss_lr0.001_hlayers_1_window_7/events.out.tfevents.1617187569.8b696378d8c0.66.9 (deflated 73%)\n",
            "  adding: content/runs/Mar31_10-46-08_8b696378d8c0/test_loss_lr0.001_hlayers_7_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-46-08_8b696378d8c0/test_loss_lr0.001_hlayers_7_window_7/events.out.tfevents.1617187719.8b696378d8c0.66.11 (deflated 48%)\n",
            "  adding: content/runs/Mar31_10-46-08_8b696378d8c0/loss_lr0.001_hlayers_7_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_10-46-08_8b696378d8c0/loss_lr0.001_hlayers_7_window_7/events.out.tfevents.1617187719.8b696378d8c0.66.10 (deflated 46%)\n",
            "  adding: content/runs/Mar31_11-00-14_8b696378d8c0/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-14_8b696378d8c0/loss_lr0.001_hlayers_1_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-14_8b696378d8c0/loss_lr0.001_hlayers_1_window_7/events.out.tfevents.1617188414.8b696378d8c0.66.19 (deflated 10%)\n",
            "  adding: content/runs/Mar31_11-00-14_8b696378d8c0/events.out.tfevents.1617188414.8b696378d8c0.66.18 (deflated 5%)\n",
            "  adding: content/runs/Mar31_11-00-14_8b696378d8c0/test_loss_lr0.001_hlayers_1_window_7/ (stored 0%)\n",
            "  adding: content/runs/Mar31_11-00-14_8b696378d8c0/test_loss_lr0.001_hlayers_1_window_7/events.out.tfevents.1617188414.8b696378d8c0.66.20 (deflated 10%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2999d338-25e8-4892-9b1e-910a07ede8d5\", \"file.zip\", 96728)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1oaZc9LIke8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}